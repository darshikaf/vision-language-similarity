# Vision-Language Similarity Service

Production-ready vision-language similarity evaluation service using OpenCLIP models. Calculates CLIP scores for image-text semantic similarity with FastAPI web service and optional Ray Serve deployment for ML-native scaling.

## Core Features

- **CLIP Score Evaluation**: Semantic similarity scoring using OpenCLIP (ViT-B-32, ViT-L-14)
- **Batch Processing**: 5.29x speedup through async concurrent processing
- **Dual Deployment**: Standard FastAPI or Ray Serve with autoscaling
- **Production Observability**: Prometheus metrics, Grafana dashboards, distributed tracing
- **Error Recovery**: Graceful failure handling in batch operations
- **Performance Tools**: Profiling, load testing, optimization analysis

## Architecture

### Core Components

**Service Layer** (`service/`):
- FastAPI REST API with Ray Serve integration
- Evaluation and system management endpoints

**Core ML Engine** (`service/core/ml/`):
- `engines/`: CLIP evaluation orchestration with async processing
- `models/`: OpenCLIP model implementations with mixed precision
- `utils/`: Image processing, metrics recording, result building

**Supporting Components**:
- Device management (CUDA/MPS/CPU auto-selection)
- Built-in model configurations with environment variable overrides
- Prometheus metrics and OpenTelemetry tracing

### Deployment Options

**Standard FastAPI**: Fast development, simple container deployment
**Ray Serve**: ML-native autoscaling, intelligent traffic management, A/B testing

## API Endpoints

- `GET /evaluator/health`: Service health check
- `POST /evaluator/v1/evaluation/single`: Single image-text evaluation
- `POST /evaluator/v1/evaluation/batch`: Batch image-text evaluation
- `GET /evaluator/metrics`: Prometheus metrics
- `GET /evaluator/docs`: Interactive API documentation

## Performance

- **Latency**: 172ms per image (ViT-B-32)
- **Batch Speedup**: 5.29x through async concurrency
- **Memory**: 2.5-3GB base + 50-100MB per concurrent request
- **Scaling**: Single requests to hundreds of millions daily

## Technologies

- **ML**: PyTorch, OpenCLIP, mixed precision inference
- **Web**: FastAPI async/await, Ray Serve
- **Observability**: Prometheus, Grafana, OpenTelemetry, Jaeger
- **Development**: Docker, pytest, ruff, Make

## Quick Start

```bash
make dev-setup                    # Setup environment
make run-local                    # Start FastAPI service
make run-local-ray               # Start Ray Serve
make run-local-otel              # Start with observability stack
make run-unit-test-suite-local   # Run tests
```

## CLI Tool

`cli/evaluation_cli.py` - Batch CSV evaluation with performance comparison between single and batch processing modes.